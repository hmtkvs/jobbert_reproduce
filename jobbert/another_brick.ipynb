{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertModel, AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "537c64b1",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaddbef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>positive_skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7638</th>\n",
       "      <td>insurance risk consultant</td>\n",
       "      <td>advise on risk management, analyse financial ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       job_title  \\\n",
       "7638  insurance risk consultant    \n",
       "\n",
       "                                         positive_skill  \n",
       "7638   advise on risk management, analyse financial ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data frame with two columns: title, positive_skill\n",
    "df = pd.read_csv(\"v1401_1_4_train.csv\")\n",
    "df[['InputConcat']] = df[['InputConcat']].astype(str)\n",
    "df_split = df['InputConcat'].str.split('<h>', expand=True)\n",
    "dfIC = pd.concat([df, df_split], axis=1)\n",
    "df_ = dfIC[[0, 2]]\n",
    "df_raw = df_.rename(columns={0:'job_title',2:'positive_skill'})\n",
    "df_raw = df_raw[~df_raw.apply(lambda x: x.str.strip() == '', axis=1).any(axis=1)]\n",
    "df_raw.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "93278640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>positive_skill_x</th>\n",
       "      <th>positive_skill_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture editor</td>\n",
       "      <td>meet deadlines, adapt to type of media, perfo...</td>\n",
       "      <td>meet deadlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture editor</td>\n",
       "      <td>meet deadlines, adapt to type of media, perfo...</td>\n",
       "      <td>adapt to type of media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture editor</td>\n",
       "      <td>meet deadlines, adapt to type of media, perfo...</td>\n",
       "      <td>perform image editing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture editor</td>\n",
       "      <td>meet deadlines, adapt to type of media, perfo...</td>\n",
       "      <td>edit photographs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture editor</td>\n",
       "      <td>meet deadlines, adapt to type of media, perfo...</td>\n",
       "      <td>negotiate exploitation rights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture editor</td>\n",
       "      <td>meet deadlines, adapt to type of media, perfo...</td>\n",
       "      <td>follow ethical code of conduct of journalists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture editor</td>\n",
       "      <td>meet deadlines, adapt to type of media, perfo...</td>\n",
       "      <td>supervise staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture editor</td>\n",
       "      <td>meet deadlines, adapt to type of media, perfo...</td>\n",
       "      <td>select photos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture editor</td>\n",
       "      <td>meet deadlines, adapt to type of media, perfo...</td>\n",
       "      <td>consult with editor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture editor</td>\n",
       "      <td>meet deadlines, adapt to type of media, perfo...</td>\n",
       "      <td>edit negatives</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         job_title                                   positive_skill_x  \\\n",
       "0  picture editor    meet deadlines, adapt to type of media, perfo...   \n",
       "0  picture editor    meet deadlines, adapt to type of media, perfo...   \n",
       "0  picture editor    meet deadlines, adapt to type of media, perfo...   \n",
       "0  picture editor    meet deadlines, adapt to type of media, perfo...   \n",
       "0  picture editor    meet deadlines, adapt to type of media, perfo...   \n",
       "0  picture editor    meet deadlines, adapt to type of media, perfo...   \n",
       "0  picture editor    meet deadlines, adapt to type of media, perfo...   \n",
       "0  picture editor    meet deadlines, adapt to type of media, perfo...   \n",
       "0  picture editor    meet deadlines, adapt to type of media, perfo...   \n",
       "0  picture editor    meet deadlines, adapt to type of media, perfo...   \n",
       "\n",
       "                                positive_skill_y  \n",
       "0                                 meet deadlines  \n",
       "0                         adapt to type of media  \n",
       "0                          perform image editing  \n",
       "0                               edit photographs  \n",
       "0                  negotiate exploitation rights  \n",
       "0  follow ethical code of conduct of journalists  \n",
       "0                                supervise staff  \n",
       "0                                  select photos  \n",
       "0                            consult with editor  \n",
       "0                                 edit negatives  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.merge(df_raw['positive_skill'].str.strip().str.split(', ').explode(), left_index=True, right_index=True).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65146d08",
   "metadata": {},
   "source": [
    "## Dataset Clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a2f2d5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41449, 2), (10363, 2))"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class JobTitleDataset(Dataset):\n",
    "    def __init__(self, data_frame, tokenizer, max_token_len, K):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "        self.K = K\n",
    "        self.training_pairs = self._prepare_training_data(data_frame)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.training_pairs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        job_title, positive_skill = self.training_pairs[index]['job_title'], self.training_pairs[index]['positive_skill']\n",
    "\n",
    "        job_title_encoding = self.tokenizer.encode_plus(\n",
    "          job_title,\n",
    "          add_special_tokens=False,\n",
    "          max_length=self.max_token_len,\n",
    "          return_token_type_ids=False,\n",
    "          padding=\"max_length\",\n",
    "          truncation=True,\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        positive_skill_IDs = self.skill_to_id[positive_skill]\n",
    "\n",
    "        random_negatives = self.skill_frequencies.sample(n=self.K, weights=self.skill_frequencies.values).index.tolist()\n",
    "        negative_skills_IDs = [self.skill_to_id[item] for item in random_negatives]\n",
    "\n",
    "        return dict(\n",
    "          input_job_title=job_title_encoding[\"input_ids\"].flatten(),\n",
    "          positive_skill=torch.tensor(positive_skill_IDs),#.unsqueeze(0),\n",
    "          negative_skills=torch.tensor(negative_skills_IDs),#.unsqueeze(0)\n",
    "                  )\n",
    "\n",
    "    def _prepare_training_data(self, df):\n",
    "        all_skills_series = df['positive_skill'].str.strip().str.split(', ').explode()\n",
    "        all_skills_series = all_skills_series.apply(lambda x: x.strip())\n",
    "        all_unique_skills = all_skills_series.unique().tolist()\n",
    "        self.skill_frequencies = all_skills_series.value_counts(normalize=True) ** 0.75\n",
    "        self.num_of_unique_skills = len(all_unique_skills)\n",
    "        self.skill_to_id = {skill: i for i, skill in enumerate(all_unique_skills)}\n",
    "\n",
    "        df_ = df.merge(all_skills_series, left_index=True, right_index=True)\n",
    "        df_new = df_.rename(columns={'positive_skill_y':'positive_skill'})\n",
    "        df_new.drop(columns=['positive_skill_x'], inplace=True)\n",
    "        df_new = df_new.sample(frac=1).reset_index(drop=True)\n",
    "        data_dict = df_new[['job_title', 'positive_skill']].to_dict('records')\n",
    "        return data_dict\n",
    "\n",
    "train, validate = np.split(df_raw.sample(frac=1, random_state=42), [int(.8*len(df_raw))])\n",
    "train.shape, validate.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e65c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ed94ee64",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hz/jfqn6dnx7qxdgl_fsqhmm8940000gn/T/ipykernel_18456/1609689800.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_job_title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/hz/jfqn6dnx7qxdgl_fsqhmm8940000gn/T/ipykernel_18456/1609689800.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_job_title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/hz/jfqn6dnx7qxdgl_fsqhmm8940000gn/T/ipykernel_18456/1774961063.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     24\u001b[0m         )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mrandom_negatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskill_frequencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskill_frequencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mnegative_skills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskill_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_negatives\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   5324\u001b[0m                 )\n\u001b[1;32m   5325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5326\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5327\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight vector may not include `inf` values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5492\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5493\u001b[0;31m         \u001b[0mres_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_op_result_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indexed_same\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max([len(item['input_job_title'].nonzero()) for item in ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09da3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_skills_series = df['positive_skill'].str.strip().str.split(', ').explode()\n",
    "# all_skills_series = all_skills_series.apply(lambda x: x.strip())\n",
    "# all_unique_skills = all_skills_series.unique().tolist()\n",
    "# skill_frequencies = all_skills_series.value_counts(normalize=True) ** 0.75\n",
    "\n",
    "# skill_to_id = {skill: i for i, skill in enumerate(all_unique_skills)}\n",
    "\n",
    "# df_ = df.merge(all_skills_series, left_index=True, right_index=True)\n",
    "# df_new = df_.rename(columns={'positive_skill_y':'positive_skill'})\n",
    "# df_new.drop(columns=['positive_skill_x'], inplace=True)\n",
    "# df_new = df_new.sample(frac=1).reset_index(drop=True)\n",
    "# df_new['positive_skill_IDs'] = df_new['positive_skill'].apply(lambda x: skill_to_id[x])\n",
    "# data_dict = df_new[['job_title', 'positive_skill_IDs']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd0660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "7d6894ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size = 100, Validation Size = 20\n"
     ]
    }
   ],
   "source": [
    "training_pairs, validation_pairs, all_skills_series = get_training_pairs(df_raw, 100)\n",
    "print(f'Train Size = {len(training_pairs)}, Validation Size = {len(validation_pairs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34e1ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = JobTitleDataset(df_raw, tokenizer, max_token_len=16, K=5)\n",
    "train_loader = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2103911",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "f2905f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.1834, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Jobbert_neg_sampling(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, vocab_size):\n",
    "        super(Jobbert_neg_sampling, self).__init__()\n",
    "\n",
    "        self.bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.embeddings_context = nn.Embedding(vocab_size, embedding_size) # torch zeros\n",
    "\n",
    "        # # Initialize the gating layer\n",
    "        self.gating = nn.Linear(self.bert_model.config.hidden_size, 1)\n",
    "\n",
    "        # # Initialize the layers   \n",
    "        self.mlp_layers = nn.Sequential(\n",
    "                        nn.Linear(self.bert_model.config.hidden_size, 768),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(768, 300)\n",
    "                        )\n",
    "        \n",
    "        self.criteron = nn.NLLLoss()\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if module.weight.shape[1] == 1:\n",
    "                nn.init.uniform_(module.weight, -math.sqrt(1/768), math.sqrt(1/768))\n",
    "                nn.init.uniform_(module.bias, -1, 1)\n",
    "            else:\n",
    "                nn.init.uniform_(module.weight, -math.sqrt(1/768), math.sqrt(1/768))\n",
    "                nn.init.uniform_(module.bias, -math.sqrt(1/300), math.sqrt(1/300))\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        debug =  not True\n",
    "\n",
    "        t = data['input_job_title']\n",
    "        u_j = self.embeddings_context(data['positive_skill'])\n",
    "        u_k = self.embeddings_context(data['negative_skills'])\n",
    "\n",
    "        if debug:\n",
    "            print('u_j.shape: ', u_j.shape)\n",
    "            print('u_k.shape: ', u_k.shape) \n",
    "\n",
    "        # # Get the BERT embeddings\n",
    "        bert_output = self.bert_model(t)['last_hidden_state']\n",
    "        # # Get the gating scores\n",
    "        x = self.gating(bert_output).sigmoid()\n",
    "        # # Get the averaged sum of the gated embeddings\n",
    "        det = x.sum(dim=1)\n",
    "        gating_scores = x / det.unsqueeze(dim=-1)\n",
    "        # # Get the input embeddings\n",
    "        input_embs = gating_scores * bert_output\n",
    "        input_embs = input_embs.sum(dim=1)\n",
    "        input_embs = self.mlp_layers(input_embs)\n",
    "        if debug:print('input_embs.shape: ', input_embs.shape)\n",
    "       \n",
    "       # Positive samples\n",
    "        emb_context = torch.mul(u_j, input_embs)\n",
    "        if debug:print('pos_matx.shape: ', emb_context.shape)\n",
    "\n",
    "        emb_product = torch.sum(emb_context, dim=1)          # bs\n",
    "        if debug:print('emb_product.shape: ', emb_product.shape)\n",
    "\n",
    "        out_loss = F.logsigmoid(emb_product)                      # bs\n",
    "        if debug:print('out_loss.shape: ', out_loss.shape)\n",
    "\n",
    "        # Negative samples\n",
    "        if debug:print('input_embs.unsqueeze(2).shape: ', input_embs.unsqueeze(2).shape)\n",
    "        emb_product_neg_samples = torch.bmm(u_k.neg(), input_embs.unsqueeze(2))\n",
    "        if debug:print('emb_product_neg_samples.shape: ', emb_product_neg_samples.shape)\n",
    "        noise_loss = F.logsigmoid(emb_product_neg_samples).squeeze(2).sum(1)\n",
    "        if debug:print('noise_loss.shape: ', noise_loss.shape)\n",
    "\n",
    "        if debug:print('*'*100)\n",
    "\n",
    "        total_loss = out_loss + noise_loss\n",
    "        if debug:print('total_loss: ', total_loss)\n",
    "\n",
    "        mean_loss = -(out_loss + noise_loss).mean()\n",
    "        if debug:print('mean_loss: ', mean_loss)\n",
    "\n",
    "        # with loss function ???\n",
    "        #nll_loss = self.criteron(emb_product, emb_product_neg_samples.squeeze(2).sum(1).long())\n",
    "        #if debug:print(\"nll_loss: \", nll_loss)\n",
    "\n",
    "        return mean_loss\n",
    "    \n",
    "\n",
    "model = Jobbert_neg_sampling(embedding_size=300, vocab_size=num_of_unique_skills)\n",
    "data_row = next(iter(train_loader))\n",
    "model(data_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "92e8e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "batch_size = 8\n",
    "num_epochs = 3\n",
    "\n",
    "# get training parameters\n",
    "num_of_unique_skills = len(all_skills_series.unique().tolist())\n",
    "\n",
    "# Initialize the model\n",
    "model = Jobbert_neg_sampling(embedding_size=300, vocab_size=num_of_unique_skills)\n",
    "\n",
    "\n",
    "# Initialize the data loader\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "df_train, df_validate = np.split(df_raw.sample(frac=1, random_state=42), [int(.8*len(df_raw))])\n",
    "\n",
    "\n",
    "train_dataset = JobTitleDataset(df_train, tokenizer, max_token_len=16, K=5)\n",
    "train_loader = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = JobTitleDataset(df_validate, tokenizer, max_token_len=16, K=5)\n",
    "val_loader = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Initialize the optimizers\n",
    "optimizer_gating_mlp = optim.SGD(model.mlp_layers.parameters(), lr=0.05)\n",
    "optimizer_context_matrix = optim.Adagrad(model.embeddings_context.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "1d7e50ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_T loss:  tensor(21.9575, grad_fn=<NegBackward0>)\n",
      "J_T loss:  tensor(7.5741, grad_fn=<NegBackward0>)\n",
      "J_T loss:  tensor(7.0884, grad_fn=<NegBackward0>)\n",
      "J_T loss:  tensor(5.4644, grad_fn=<NegBackward0>)\n",
      "J_T loss:  tensor(4.6789, grad_fn=<NegBackward0>)\n",
      "J_T loss:  tensor(4.2801, grad_fn=<NegBackward0>)\n",
      "J_T loss:  tensor(4.4234, grad_fn=<NegBackward0>)\n",
      "J_T loss:  tensor(5.6373, grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hz/jfqn6dnx7qxdgl_fsqhmm8940000gn/T/ipykernel_18456/3455889098.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define your training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i, input in enumerate(train_loader):\n",
    "        # clear gradients\n",
    "        optimizer_gating_mlp.zero_grad()\n",
    "        optimizer_context_matrix.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        loss = model(input)\n",
    "        print('J_T loss: ', loss)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer_gating_mlp.step()\n",
    "        optimizer_context_matrix.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #EVALUATION\n",
    "        # res = J_T.mean(dim=1) @ skill_emb.float().T\n",
    "        # res.shape\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch}: loss={total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf8cb45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e0a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11c20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49b54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "604b1538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32c8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f0904a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "embeddings_context = nn.Embedding(300, num_of_unique_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236fae47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1b4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c658b555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3268],\n",
       "        [ 7508],\n",
       "        [20356],\n",
       "        [10456],\n",
       "        [10693],\n",
       "        [ 1047],\n",
       "        [ 2726],\n",
       "        [20504]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_row['positive_skill']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a00c9833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3088, -1.4271, -1.3817,  ..., -1.3544, -1.3891, -1.3470],\n",
       "         [-1.3101, -1.4231, -1.3818,  ..., -1.3575, -1.3892, -1.3482],\n",
       "         [-1.3091, -1.4254, -1.3815,  ..., -1.3578, -1.3890, -1.3499],\n",
       "         ...,\n",
       "         [-1.3070, -1.4166, -1.3815,  ..., -1.3611, -1.3890, -1.3477],\n",
       "         [-1.3082, -1.4170, -1.3813,  ..., -1.3596, -1.3891, -1.3478],\n",
       "         [-1.3073, -1.4164, -1.3814,  ..., -1.3576, -1.3891, -1.3490]],\n",
       "\n",
       "        [[-1.4138, -1.3668, -1.4478,  ..., -1.3653, -1.3901, -1.3493],\n",
       "         [-1.4146, -1.3692, -1.4492,  ..., -1.3683, -1.3901, -1.3508],\n",
       "         [-1.4150, -1.3720, -1.4478,  ..., -1.3697, -1.3898, -1.3491],\n",
       "         ...,\n",
       "         [-1.4146, -1.3720, -1.4509,  ..., -1.3701, -1.3899, -1.3497],\n",
       "         [-1.4142, -1.3718, -1.4526,  ..., -1.3689, -1.3900, -1.3496],\n",
       "         [-1.4146, -1.3719, -1.4521,  ..., -1.3677, -1.3901, -1.3508]],\n",
       "\n",
       "        [[-1.3986, -1.3286, -1.3754,  ..., -1.3879, -1.3751, -1.3770],\n",
       "         [-1.3990, -1.3391, -1.3754,  ..., -1.3873, -1.3765, -1.3778],\n",
       "         [-1.3992, -1.3448, -1.3754,  ..., -1.3876, -1.3759, -1.3771],\n",
       "         ...,\n",
       "         [-1.3990, -1.3448, -1.3749,  ..., -1.3875, -1.3756, -1.3772],\n",
       "         [-1.3988, -1.3438, -1.3747,  ..., -1.3876, -1.3753, -1.3772],\n",
       "         [-1.3990, -1.3447, -1.3747,  ..., -1.3877, -1.3751, -1.3775]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.4867, -1.3780, -1.3667,  ..., -1.4148, -1.4224, -1.3666],\n",
       "         [-1.4887, -1.3783, -1.3663,  ..., -1.4139, -1.4231, -1.3672],\n",
       "         [-1.4855, -1.3786, -1.3667,  ..., -1.4125, -1.4258, -1.3663],\n",
       "         ...,\n",
       "         [-1.4890, -1.3801, -1.3660,  ..., -1.4083, -1.4207, -1.3669],\n",
       "         [-1.4873, -1.3800, -1.3656,  ..., -1.4100, -1.4217, -1.3669],\n",
       "         [-1.4887, -1.3801, -1.3657,  ..., -1.4116, -1.4221, -1.3675]],\n",
       "\n",
       "        [[-1.5251, -1.3910, -1.3916,  ..., -1.3756, -1.3669, -1.3436],\n",
       "         [-1.5260, -1.3897, -1.3913,  ..., -1.3782, -1.3671, -1.3449],\n",
       "         [-1.5250, -1.3909, -1.3918,  ..., -1.3769, -1.3675, -1.3469],\n",
       "         ...,\n",
       "         [-1.5293, -1.3897, -1.3918,  ..., -1.3780, -1.3676, -1.3447],\n",
       "         [-1.5269, -1.3898, -1.3920,  ..., -1.3776, -1.3670, -1.3447],\n",
       "         [-1.5287, -1.3897, -1.3919,  ..., -1.3769, -1.3667, -1.3460]],\n",
       "\n",
       "        [[-1.2849, -1.3870, -1.3729,  ..., -1.3754, -1.3626, -1.4231],\n",
       "         [-1.2856, -1.3870, -1.3731,  ..., -1.3761, -1.3635, -1.4219],\n",
       "         [-1.2847, -1.3870, -1.3726,  ..., -1.3768, -1.3634, -1.4206],\n",
       "         ...,\n",
       "         [-1.2818, -1.3868, -1.3725,  ..., -1.3778, -1.3636, -1.4227],\n",
       "         [-1.2834, -1.3868, -1.3721,  ..., -1.3774, -1.3629, -1.4228],\n",
       "         [-1.2822, -1.3868, -1.3722,  ..., -1.3767, -1.3626, -1.4216]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " predictions = model(next(iter(train_loader)))\n",
    " predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b42b8916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 300])\n",
      "torch.Size([16, 300])\n",
      "torch.Size([16, 300])\n",
      "torch.Size([16, 300])\n",
      "torch.Size([16, 300])\n",
      "torch.Size([16, 300])\n",
      "torch.Size([16, 300])\n",
      "torch.Size([16, 300])\n"
     ]
    }
   ],
   "source": [
    " predictions = model(next(iter(data_loader)))\n",
    "\n",
    "# Compute the MRR across all queries\n",
    "mrr = 0\n",
    "num_queries = 0\n",
    "for query in predictions:\n",
    "    print(query.shape)\n",
    "    # Sort the predicted scores for this query in descending order\n",
    "    ranked_scores, ranked_indices = torch.sort(query, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0ce7aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 300])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d52dca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, validation_set):\n",
    "    # Evaluate the model on the validation set and get the predictions\n",
    "    predictions = model(validation_set)\n",
    "\n",
    "    # Compute the MRR across all queries\n",
    "    mrr = 0\n",
    "    num_queries = 0\n",
    "    for query in predictions:\n",
    "        # Sort the predicted scores for this query in descending order\n",
    "        ranked_scores, ranked_indices = torch.sort(query, descending=True)\n",
    "\n",
    "        # Find the rank of the first correct prediction (i.e., the reciprocal rank)\n",
    "        correct_index = ranked_indices == 0\n",
    "        reciprocal_rank = 1 / (correct_index.nonzero(as_tuple=True)[0][0] + 1)\n",
    "\n",
    "        # Add the reciprocal rank to the total MRR and increment the query count\n",
    "        mrr += reciprocal_rank\n",
    "        num_queries += 1\n",
    "\n",
    "    # Compute the mean MRR across all queries\n",
    "    mean_mrr = mrr / num_queries\n",
    "\n",
    "    # Return the negative mean MRR as the loss\n",
    "    return -mean_mrr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84d8be2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.)\n",
      "tensor(-1.)\n",
      "tensor(-1.)\n",
      "tensor(-1.)\n",
      "tensor(-1.)\n",
      "tensor(-1.)\n",
      "tensor(-1.)\n",
      "tensor(-1.)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hz/jfqn6dnx7qxdgl_fsqhmm8940000gn/T/ipykernel_12144/1636971306.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m    \u001b[0mcalc_mrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_mrr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/hz/jfqn6dnx7qxdgl_fsqhmm8940000gn/T/ipykernel_12144/3994935265.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(model, validation_set)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Evaluate the model on the validation set and get the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Compute the MRR across all queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/hz/jfqn6dnx7qxdgl_fsqhmm8940000gn/T/ipykernel_12144/2176515139.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# # Get the BERT embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_hidden_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;31m# # Get the gating scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         )\n\u001b[0;32m--> 996\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 )\n\u001b[1;32m    584\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    586\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         )\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " for i, input in enumerate(val_loader):\n",
    "    calc_mrr = compute_loss(model, input)\n",
    "    print(calc_mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9b67b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.keys():  dict_keys(['input_job_title', 'positive_skill', 'negative_skills'])\n",
      "input_embs.shape:  torch.Size([2, 16, 300])\n",
      "u_j.shape:  torch.Size([2, 1, 300])\n",
      "u_k.shape:  torch.Size([2, 1, 5, 300])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'compute_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hz/jfqn6dnx7qxdgl_fsqhmm8940000gn/T/ipykernel_2308/2449634120.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_loss' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    for batch in data_loader:\n",
    "        # Zero the gradients for all parameters\n",
    "        optimizer_gating_mechanism.zero_grad()\n",
    "        optimizer_mlp_weights.zero_grad()\n",
    "        optimizer_context_matrix.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(batch)\n",
    "        loss = compute_loss(output)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer_gating_mechanism.step()\n",
    "        optimizer_mlp_weights.step()\n",
    "        optimizer_context_matrix.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76f944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e0cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d16c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c73b29b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "93cb3295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 300])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embs = torch.rand(32, 16, 300)\n",
    "u_j = torch.rand(32, 1, 300)\n",
    "u_k = torch.rand(32, 1, 5, 300)\n",
    "\n",
    "pos_mult = torch.mul(u_j, input_embs)\n",
    "\n",
    "aux_embs = input_embs.unsqueeze(2).expand(-1, -1, 5, -1)\n",
    "a = (u_k * aux_embs).sum(dim=2).neg()\n",
    "\n",
    "J_T = F.logsigmoid(pos_mult) + F.logsigmoid(a)\n",
    "J_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "dd6a367b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 300])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_mul.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "dffade07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 300])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (u_k * aux_embs).sum(dim=2).neg()\n",
    "a.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "306c9fac",
   "metadata": {},
   "source": [
    "### Get DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02386fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000])\n",
      "torch.Size([1000, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 902,   68, 6990, 6700, 2353],\n",
       "        [ 365, 3593,  860,  102, 6111],\n",
       "        [3620,  479, 5013, 1882,  853],\n",
       "        ...,\n",
       "        [2831,   91, 5666, 5576, 1020],\n",
       "        [  44, 3050,  850,  930, 1240],\n",
       "        [ 199, 2204, 3603, 5050, 1339]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Example Usage\n",
    "neg_samples = torch.multinomial(noise_dist, K * len(df), replacement=True)\n",
    "print(neg_samples.shape)\n",
    "neg_samples = neg_samples.view(len(df), K)\n",
    "print(neg_samples.shape)\n",
    "neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b4f57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_skills_to_ids(all_unique_skills):\n",
    "    \"\"\"\n",
    "    Convert the skills to ids.\n",
    "    \"\"\"\n",
    "    skill_to_id = {skill: i for i, skill in enumerate(all_unique_skills)}\n",
    "    id_to_skill = {i: skill for i, skill in enumerate(all_unique_skills)}\n",
    "    return skill_to_id, id_to_skill\n",
    "\n",
    "skill_to_id, id_to_skill = convert_skills_to_ids(all_unique_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c2c6edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>positive_skill</th>\n",
       "      <th>positive_skill_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building cleaner</td>\n",
       "      <td>maintain cleaning equipment</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>power plant manager</td>\n",
       "      <td>manage budgets</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Branch Manager</td>\n",
       "      <td>effective sales</td>\n",
       "      <td>2847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>energy systems engineer</td>\n",
       "      <td>determine appropriate heating and cooling system</td>\n",
       "      <td>4551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brand Manager</td>\n",
       "      <td>Organización de eventos</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14083</th>\n",
       "      <td>Project Engineer</td>\n",
       "      <td>CANoe</td>\n",
       "      <td>2790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14084</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>then we would love to hear from you.  \\n \\n Jo...</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14085</th>\n",
       "      <td>Sales Engineer</td>\n",
       "      <td>VPN</td>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14086</th>\n",
       "      <td>integrated circuit design engineer</td>\n",
       "      <td>electronic equipment standards</td>\n",
       "      <td>2515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14087</th>\n",
       "      <td>power plant manager</td>\n",
       "      <td>define manufacturing quality criteria</td>\n",
       "      <td>3377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14088 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 job_title  \\\n",
       "0                        building cleaner    \n",
       "1                     power plant manager    \n",
       "2                          Branch Manager    \n",
       "3                 energy systems engineer    \n",
       "4                           Brand Manager    \n",
       "...                                    ...   \n",
       "14083                    Project Engineer    \n",
       "14084                       Web Developer    \n",
       "14085                      Sales Engineer    \n",
       "14086  integrated circuit design engineer    \n",
       "14087                 power plant manager    \n",
       "\n",
       "                                          positive_skill  positive_skill_IDs  \n",
       "0                            maintain cleaning equipment                 658  \n",
       "1                                         manage budgets                  90  \n",
       "2                                        effective sales                2847  \n",
       "3       determine appropriate heating and cooling system                4551  \n",
       "4                                Organización de eventos                1007  \n",
       "...                                                  ...                 ...  \n",
       "14083                                              CANoe                2790  \n",
       "14084  then we would love to hear from you.  \\n \\n Jo...                1860  \n",
       "14085                                                VPN                1296  \n",
       "14086                     electronic equipment standards                2515  \n",
       "14087              define manufacturing quality criteria                3377  \n",
       "\n",
       "[14088 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = df.merge(all_skills_series, left_index=True, right_index=True)\n",
    "df_new = df_.rename(columns={'positive_skill_y':'positive_skill'})\n",
    "df_new.drop(columns=['positive_skill_x'], inplace=True)\n",
    "df_new = df_new.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_new['positive_skill_IDs'] = df_new['positive_skill'].apply(lambda x: skill_to_id[x])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9bbab1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2668, 1519, 190, 4273, 2238]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_frequencies = all_skills_series.value_counts(normalize=True) ** 0.75\n",
    "random_negatives = skill_frequencies.sample(n=K, weights=skill_frequencies.values).index.tolist()\n",
    "random_negatives\n",
    "\n",
    "[skill_to_id[item] for item in random_negatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d865b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9396d7115f22497d66c05bbd895d6b4e4b56fe280c4ac2c90db39aff1eb9bd95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
